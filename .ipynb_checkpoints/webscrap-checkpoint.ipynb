{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "requested-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "international-turkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_for_100(url,pages):\n",
    "    for page_number in range(1,pages):\n",
    "        url_page = requests.get(url+str(page_number))\n",
    "        soup = BeautifulSoup(url_page.content, 'html.parser')\n",
    "        href_link_list =[]\n",
    "        for link in soup.find_all('a', class_='bookTitle') :\n",
    "            if link.has_attr('href'):\n",
    "                href_link_list.append(link.attrs['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "funded-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_100_links = get_links_for_100('https://www.goodreads.com/list/show/6.Best_Books_of_the_20th_Century?page=',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-architecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = requests.get(\"https://www.goodreads.com/list/show/6.Best_Books_of_the_20th_Century?page=1\")\n",
    "soup = BeautifulSoup(url_list.content, 'html.parser')\n",
    "href_link_list =[]\n",
    "for link in soup.find_all('a', class_='bookTitle') :\n",
    "    if link.has_attr('href'):\n",
    "        href_link_list.append(link.attrs['href'])\n",
    "    \n",
    "url_detail = requests.get(\"https://www.goodreads.com\" + str(href_link_list[0]))\n",
    "soup_detail = BeautifulSoup(url_detail.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-affiliate",
   "metadata": {},
   "source": [
    "# Detail view "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "provincial-edwards",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for one book implement it in a for lopp with url_list\n",
    "url2 = requests.get(\"https://www.goodreads.com/book/show/2657.To_Kill_a_Mockingbird\")\n",
    "soup_detail = BeautifulSoup(url2.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "trying-anger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['To Kill a Mockingbird']\n",
      "['Harper Lee']\n",
      "[['95,083']]\n",
      "[['4,747']]\n",
      "['4.28']\n",
      "['324']\n",
      "['1960']\n",
      "[['Original', 'Title'], ['Edition', 'Language'], ['Series'], ['Characters'], ['Setting'], ['Literary', 'Awards'], ['Other', 'Editions', '(649)']]\n",
      "['Pulitzer Prize for Fiction (1961), Audie Award for Classic (2007), National Book Award Finalist for Fiction (1961), Alabama Author Award for Fiction (1961)']\n",
      "[['Classics', 'Fiction', 'Historical']]\n"
     ]
    }
   ],
   "source": [
    "#Extract data write in a function & find the class names etc\n",
    "#get the book title\n",
    "book_titles = []\n",
    "try:\n",
    "title = soup_detail.find(\"h1\", {\"id\":\"bookTitle\"}).text.replace(\"\\n\",\"\").replace(\"      \",\"\")\n",
    "book_titles.append(title)\n",
    "print(book_titles)\n",
    "\n",
    "\n",
    "#get the book author\n",
    "book_author = []\n",
    "author = soup_detail.find(\"div\", {\"class\":\"authorName__container\"}).text.replace(\"\\n\",\"\")\n",
    "book_author.append(author)\n",
    "print(book_author)\n",
    "\n",
    "#get the book reviews\n",
    "book_reviews = []\n",
    "review = soup_detail.find(\"meta\", {\"itemprop\":\"reviewCount\"}).text.replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "only_numbers = re.findall(\"[0-9]+,[0-9]+\", review)\n",
    "book_reviews.append(only_numbers)\n",
    "print(book_reviews)\n",
    "\n",
    "# get ratings\n",
    "book_ratings = []\n",
    "rating = soup_detail.find(\"meta\", {\"itemprop\":\"ratingCount\"}).text.replace(\"\\n\",\"\")\n",
    "only_numbers = re.findall(\"[0-9]+,[0-9]+\", rating)\n",
    "book_ratings.append(only_numbers)\n",
    "print(book_ratings)\n",
    "\n",
    "# get avgratings\n",
    "book_avgratings = []\n",
    "avgrating = soup_detail.find(\"span\", {\"itemprop\":\"ratingValue\"}).text.replace(\"\\n\",\"\").replace(' ','')\n",
    "book_avgratings.append(avgrating)\n",
    "print(book_avgratings)\n",
    "\n",
    "# get pages\n",
    "book_pages = []\n",
    "page = soup_detail.find(\"span\", {\"itemprop\":\"numberOfPages\"}).text.split()\n",
    "page = page[0]\n",
    "book_pages.append(page)\n",
    "print(book_pages)\n",
    "\n",
    "# get years\n",
    "book_publish_year = []\n",
    "publish_year = soup_detail.find(\"nobr\", {\"class\":\"greyText\"}).text.replace(\"\\n\",\"\").replace(\")\",\"\").split()\n",
    "publish_year = publish_year[-1]\n",
    "book_publish_year.append(publish_year)\n",
    "print(book_publish_year)\n",
    "\n",
    "# get series # bool 1 : True 0 : False\n",
    "book_series = []\n",
    "series = soup_detail.find_all(class_= \"infoBoxRowTitle\")\n",
    "series = [serie.get_text() for serie in series]\n",
    "series = [serie.split() for serie in series]\n",
    "print(series)\n",
    "\n",
    "# get awards\n",
    "book_awards = []\n",
    "award = soup_detail.find(\"div\", {\"itemprop\":\"awards\"}).text.replace(\"\\n\",\"\")\n",
    "book_awards.append(award)\n",
    "print(book_awards)\n",
    "\n",
    "# get places\n",
    "book_places = []\n",
    "places = soup_detail.find(\"div\", {\"id\":\"bookDataBox\"}).text\n",
    "boot_places.append(places)\n",
    "\n",
    "# get genres\n",
    "book_genres = []\n",
    "genres = soup_detail.find_all(class_=\"actionLinkLite bookPageGenreLink\")\n",
    "genres = genres[:3]\n",
    "genres = [genre.get_text() for genre in genres]\n",
    "book_genres.append(genres)\n",
    "print(book_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "prepared-wheat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Original TitleTo Kill a Mockingbird Edition LanguageEnglishSeriesTo Kill a Mockingbird CharactersScout Finch', ' Atticus Finch', ' Jem Finch', ' Arthur Radley', ' Mayella Ewell...more', ' Aunt Alexandra', ' Bob Ewell', ' Calpurnia (housekeeper)', ' Tom Robinson', ' Miss Maudie Atkinson', ' Judge John Taylor', ' Dill Harris', ' Heck Tate', ' Stephanie Crawford...lessSettingMaycomb', ' Alabama', '1933(United States)Alabama(United States)Literary AwardsPulitzer Prize for Fiction (1961)', ' Audie Award for Classic (2007)', ' National Book Award Finalist for Fiction (1961)', ' Alabama Author Award for Fiction (1961)Other Editions (649)All Editions | Add a New Edition | Combine']]\n"
     ]
    }
   ],
   "source": [
    "book_places = []\n",
    "places = soup_detail.find(\"div\", {\"id\":\"bookDataBox\"}).text.replace(\"\\n\",\"\").split(',')\n",
    "book_places.append(places)\n",
    "print(book_places)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-practitioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_urls = ['https://www.goodreads.com/book/show/40961427-1984','https://www.goodreads.com/book/show/2657.To_Kill_a_Mockingbird']\n",
    "\n",
    "book_titles = []\n",
    "book_author = []\n",
    "book_reviews = []\n",
    "book_ratings = []\n",
    "book_avgratings = []\n",
    "book_pages = []\n",
    "book_publish_year = []\n",
    "book_series = []\n",
    "book_genres = []\n",
    "\n",
    "\n",
    "\n",
    "def book_title(soup):\n",
    "    for link in soup:\n",
    "        url2 = requests.get(link)\n",
    "        soup_detail = BeautifulSoup(url2.content, 'html.parser')\n",
    "\n",
    "        #get the book title\n",
    "        try:\n",
    "            title = soup_detail.find(\"h1\", {\"id\":\"bookTitle\"}).text.replace(\"\\n\",\"\").replace(\"      \",\"\")\n",
    "        except:\n",
    "            title = np.nan\n",
    "        book_titles.append(title)\n",
    "\n",
    "        #get the book author\n",
    "        try:\n",
    "            author = soup_detail.find(\"div\", {\"class\":\"authorName__container\"}).text.replace(\"\\n\",\"\")\n",
    "        except:\n",
    "            author = np.nan\n",
    "        book_author.append(author)\n",
    "\n",
    "        #get the book reviews\n",
    "        try:\n",
    "            review = soup_detail.find(\"meta\", {\"itemprop\":\"reviewCount\"}).text.replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "            help_me = re.findall(\"[0-9]+,[0-9]+\", review)\n",
    "        except:\n",
    "            help_me = np.nan\n",
    "        book_reviews.append(help_me)\n",
    "\n",
    "        # get ratings\n",
    "        try:\n",
    "            rating = soup_detail.find(\"meta\", {\"itemprop\":\"ratingCount\"}).text.replace(\"\\n\",\"\")\n",
    "            only_numbers = re.findall(\"[0-9]+,[0-9]+\", rating)\n",
    "        except:\n",
    "            only_numbers = np.nan\n",
    "        book_ratings.append(only_numbers)\n",
    "\n",
    "        #get  avg_rating\n",
    "        try:\n",
    "            avgrating = soup_detail.find(\"span\", {\"itemprop\":\"ratingValue\"}).text.replace(\"\\n\",\"\").replace(' ','')\n",
    "        except:\n",
    "            avgrating = np.nan\n",
    "        book_avgratings.append(avgrating)\n",
    "\n",
    "        #get the pages of the book\n",
    "        try:\n",
    "            page = soup_detail.find(\"span\", {\"itemprop\":\"numberOfPages\"}).text.split()\n",
    "            page = page[0]\n",
    "        except:\n",
    "            page = np.nan\n",
    "        book_pages.append(page)\n",
    "\n",
    "        # get years\n",
    "        publish_year = soup_detail.find(\"nobr\", {\"class\":\"greyText\"}).text\n",
    "        publish_year = re.findall('\\d{4}',publish_year)\n",
    "        book_publish_year.append(publish_year)\n",
    "\n",
    "        # get series\n",
    "        series = soup_detail.find_all(class_= \"infoBoxRowTitle\")\n",
    "        a = series[2].text.split()\n",
    "        if a[0] == 'Series':\n",
    "            book_series.append(True)\n",
    "        else:\n",
    "            book_series.append(False)\n",
    "\n",
    "        #improved get series\n",
    "        \n",
    "\n",
    "        \n",
    "            \n",
    "        book_places = []\n",
    "        places = soup_detail.find(\"div\", {\"id\":\"bookDataBox\"}).text.replace(\"\\n\",\"\").split(',')\n",
    "        book_places.append(places)\n",
    "        print(book_places)\n",
    "\n",
    "        # get genres\n",
    "        genres = soup_detail.find_all(class_=\"actionLinkLite bookPageGenreLink\")\n",
    "        genres = genres[:3]\n",
    "        genres = [genre.get_text() for genre in genres]\n",
    "        book_genres.append(genres)\n",
    "    \n",
    "    \n",
    "    \n",
    " \n",
    "           \n",
    "    return book_titles\n",
    "    return book_author\n",
    "    return book_reviews\n",
    "    return book_ratings\n",
    "    return book_avgratings\n",
    "    return book_pages\n",
    "    return book_publish_year\n",
    "    return book_series\n",
    "    return book_genres\n",
    "\n",
    "book_title(test_urls)\n",
    "\n",
    "print(book_titles)\n",
    "print(book_author)\n",
    "print(book_reviews)\n",
    "print(book_ratings)\n",
    "print(book_avgratings)\n",
    "print(book_publish_year)\n",
    "print(book_genres)\n",
    "print(book_series)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

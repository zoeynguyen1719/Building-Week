{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-sudan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vulnerable-communication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the imports here\n",
    "#!pip install bs4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "\n",
    "url = requests.get(\"https://www.goodreads.com/list/show/6.Best_Books_of_the_20th_Century?page=1\")\n",
    "soup = BeautifulSoup(url.content, 'html.parser')\n",
    "#print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "tutorial-terrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_for_100(url,pages):\n",
    "    for page_number in range(1,pages+1):\n",
    "        url_page = requests.get(url+str(page_number))\n",
    "        soup = BeautifulSoup(url_page.content, 'html.parser')\n",
    "        href_link_list =[]\n",
    "        for link in soup.find_all('a', class_='bookTitle') :\n",
    "            if link.has_attr('href'):\n",
    "                href_link_list.append(link.attrs['href'])\n",
    "    return href_link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "suffering-detail",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_100_links = get_links_for_100('https://www.goodreads.com/list/show/6.Best_Books_of_the_20th_Century?page=',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-belfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_urls = ['https://www.goodreads.com/book/show/40961427-1984','https://www.goodreads.com/book/show/2657.To_Kill_a_Mockingbird']\n",
    "\n",
    "book_titles = []\n",
    "book_author = []\n",
    "book_reviews = []\n",
    "book_ratings = []\n",
    "book_avgratings = []\n",
    "book_pages = []\n",
    "book_publish_year = []\n",
    "book_series = []\n",
    "book_genres = []\n",
    "book_places = []\n",
    "\n",
    "\n",
    "\n",
    "def get_detail(soup):\n",
    "    for link in soup:\n",
    "        url2 = requests.get(link)\n",
    "        soup_detail = BeautifulSoup(url2.content, 'html.parser')\n",
    "\n",
    "        #get the book title\n",
    "        try:\n",
    "            title = soup_detail.find(\"h1\", {\"id\":\"bookTitle\"}).text.replace(\"\\n\",\"\").replace(\"      \",\"\")\n",
    "        except:\n",
    "            title = np.nan\n",
    "        book_titles.append(title)\n",
    "\n",
    "        #get the book author\n",
    "        try:\n",
    "            author = soup_detail.find(\"div\", {\"class\":\"authorName__container\"}).text.replace(\"\\n\",\"\")\n",
    "        except:\n",
    "            author = np.nan\n",
    "        book_author.append(author)\n",
    "\n",
    "        #get the book reviews\n",
    "        try:\n",
    "            review = soup_detail.find(\"meta\", {\"itemprop\":\"reviewCount\"}).text.replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "            help_me = re.findall(\"[0-9]+,[0-9]+\", review)\n",
    "        except:\n",
    "            help_me = np.nan\n",
    "        book_reviews.append(help_me)\n",
    "\n",
    "        # get ratings\n",
    "        try:\n",
    "            rating = soup_detail.find(\"meta\", {\"itemprop\":\"ratingCount\"}).text.replace(\"\\n\",\"\")\n",
    "            only_numbers = re.findall(\"[0-9]+,[0-9]+\", rating)\n",
    "        except:\n",
    "            only_numbers = np.nan\n",
    "        book_ratings.append(only_numbers)\n",
    "\n",
    "        #get  avg_rating\n",
    "        try:\n",
    "            avgrating = soup_detail.find(\"span\", {\"itemprop\":\"ratingValue\"}).text.replace(\"\\n\",\"\").replace(' ','')\n",
    "        except:\n",
    "            avgrating = np.nan\n",
    "        book_avgratings.append(avgrating)\n",
    "\n",
    "        #get the pages of the book\n",
    "        try:\n",
    "            page = soup_detail.find(\"span\", {\"itemprop\":\"numberOfPages\"}).text.split()\n",
    "            page = page[0]\n",
    "        except:\n",
    "            page = np.nan\n",
    "        book_pages.append(page)\n",
    "\n",
    "        # get years\n",
    "        publish_year = soup_detail.find(\"nobr\", {\"class\":\"greyText\"}).text\n",
    "        publish_year = re.findall('\\d{4}',publish_year)\n",
    "        book_publish_year.append(publish_year)\n",
    "\n",
    "        # get series\n",
    "        #series = soup_detail.find_all(class_= \"infoBoxRowTitle\")\n",
    "        #a = series[2].text.split()\n",
    "        #if a[0] == 'Series':\n",
    "        #    book_series.append(True)\n",
    "        #else:\n",
    "        #    book_series.append(False)\n",
    "\n",
    "        #improved get series\n",
    "        new_series = soup_detail.find('div', class = )\n",
    "\n",
    "        \n",
    "        #get the places   \n",
    "        #places = soup_detail.find(\"div\", {\"id\":\"bookDataBox\"}).text.replace(\"\\n\",\"\").split(',')\n",
    "        #book_places.append(places)\n",
    "        #print(book_places)\n",
    "\n",
    "        # get genres\n",
    "        genres = soup_detail.find_all(class_=\"actionLinkLite bookPageGenreLink\")\n",
    "        genres = genres[:3]\n",
    "        genres = [genre.get_text() for genre in genres]\n",
    "        book_genres.append(genres)\n",
    "    \n",
    "    \n",
    "    \n",
    " \n",
    "           \n",
    "    return book_titles\n",
    "    return book_author\n",
    "    return book_reviews\n",
    "    return book_ratings\n",
    "    return book_avgratings\n",
    "    return book_pages\n",
    "    return book_publish_year\n",
    "    return book_series\n",
    "    return book_genres\n",
    "\n",
    "book_title(test_urls)\n",
    "\n",
    "print(book_titles)\n",
    "print(book_author)\n",
    "print(book_reviews)\n",
    "print(book_ratings)\n",
    "print(book_avgratings)\n",
    "print(book_publish_year)\n",
    "print(book_genres)\n",
    "print(book_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "important-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for one book implement it in a for lopp with url_list\n",
    "url2 = requests.get(\"https://www.goodreads.com/book/show/2657.To_Kill_a_Mockingbird\")\n",
    "soup_detail = BeautifulSoup(url2.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "destroyed-percentage",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract data write in a function & find the class names etc\n",
    "#get the book title\n",
    "\n",
    "def get_title(soup_detail):\n",
    "    try:\n",
    "        title = soup_detail.find(\"h1\", {\"id\":\"bookTitle\"}).text.replace(\"\\n\",\"\").replace(\"      \",\"\")\n",
    "    except:\n",
    "        title = np.nan\n",
    "    return title\n",
    "\n",
    "\n",
    "\n",
    "#get the book author\n",
    "\n",
    "def get_author(soup_detail):\n",
    "    try:\n",
    "        author = soup_detail.find(\"div\", {\"class\":\"authorName__container\"}).text.replace(\"\\n\",\"\")\n",
    "    except:\n",
    "        author = np.nan\n",
    "    return author\n",
    "\n",
    "\n",
    "#get the book reviews\n",
    "\n",
    "def get_review(soup_detail):\n",
    "    try:\n",
    "        review = soup_detail.find(\"meta\", {\"itemprop\":\"reviewCount\"}).text.replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "        only_numbers = re.findall(\"[0-9]+,[0-9]+\", review)\n",
    "    except:\n",
    "        review = np.nan\n",
    "    return review\n",
    "\n",
    "\n",
    "# get ratings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# get avgratings\n",
    "book_avgratings = []\n",
    "def get_avgrating(soup_detail):\n",
    "    try:\n",
    "        avgrating = soup_detail.find(\"span\", {\"itemprop\":\"ratingValue\"}).text.replace(\"\\n\",\"\").replace(' ','')\n",
    "    except:\n",
    "        avgrating = np.nan\n",
    "    return avgrating\n",
    "\n",
    "# get pages\n",
    "book_pages = []\n",
    "def get_page(soup_detail):\n",
    "    try:\n",
    "        page = soup_detail.find(\"span\", {\"itemprop\":\"numberOfPages\"}).text.split()\n",
    "        page = page[0]\n",
    "    except:\n",
    "        page = np.nan\n",
    "    return page\n",
    "\n",
    "\n",
    "# get years\n",
    "book_publish_year = []\n",
    "def get_year(soup_detail):\n",
    "    try:\n",
    "        publish_year = soup_detail.find(\"nobr\", {\"class\":\"greyText\"}).text.replace(\"\\n\",\"\").replace(\")\",\"\").split()\n",
    "        publish_year = publish_year[-1]\n",
    "    except:\n",
    "        publish_year = np.nan\n",
    "    return publish_year\n",
    "\n",
    "\n",
    "# get series # bool 1 : True 0 : False\n",
    "\n",
    "#series = soup_detail.find('div',  {\"id\":\"bookDataBox\"}).find_all('div', class_='infoBoxRowTitle')\n",
    "#series = [serie.get_text() for serie in series]\n",
    "#print(series)\n",
    "\n",
    "#if 'Series' in series:\n",
    "#    shit = True\n",
    "#else:\n",
    "#    shit = False\n",
    "\n",
    "#return shit\n",
    "\n",
    "# get awards\n",
    "def get_award(soup_detail):\n",
    "    try:\n",
    "        award = soup_detail.find(\"div\", {\"itemprop\":\"awards\"}).text.replace(\"\\n\",\"\")\n",
    "    except:\n",
    "        award = np.nan\n",
    "    return award\n",
    "\n",
    "# get places\n",
    "#book_places = []\n",
    "#places = soup_detail.find(\"div\", {\"id\":\"bookDataBox\"}).text\n",
    "#boot_places.append(places)\n",
    "\n",
    "# get genres\n",
    "book_genres = []\n",
    "genres = soup_detail.find_all(class_=\"actionLinkLite bookPageGenreLink\")\n",
    "genres = genres[:3]\n",
    "genres = [genre.get_text() for genre in genres]\n",
    "book_genres.append(genres)\n",
    "\n",
    "def get_rating(soup_detail):\n",
    "    try:\n",
    "        rating = soup_detail.find(\"meta\", {\"itemprop\":\"ratingCount\"}).text.replace(\"\\n\",\"\").split()\n",
    "        rating = rating[0]\n",
    "        \n",
    "    except:\n",
    "        rating = np.nan      \n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "written-visibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,747,968\n"
     ]
    }
   ],
   "source": [
    "test = get_rating(soup_detail)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "stock-russell",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books = pd.DataFrame()\n",
    "title = get_title(soup_detail)\n",
    "df_books['title'] = title\n",
    "df_books['author'] = get_author(soup_detail)\n",
    "df_books['ratings'] = get_rating(soup_detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "grave-sitting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  title author ratings\n",
      "0   NaN    NaN   4,747\n"
     ]
    }
   ],
   "source": [
    "print(df_books)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
